<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>jumboDev</title>
    <link rel="stylesheet" href="css/index.css">
    <link rel="stylesheet" href="css/mediaqueries.css">
    <link href="https://fonts.googleapis.com/css?family=Kanit:700,700i|Open+Sans" rel="stylesheet">
  </head>
  <body>
    <!-- page content -->
    <div id='sidebar'>
      <img class='logo' alt="" src="images/jumbo-dev-elephant.svg"/>
      <ul>
        <li><a href="#home">Home</a></li>
        <li><a href="#project">Project Background</a></li>
        <li><a href="#team">Meet The Team</a></li>
        <li><a href="#plan">Project Plan</a></li>
        <li><a href="#details">Product Details</a></li>
        
      </ul>
    </div>
    <div id="background"></div>
    <div id='main-container'>
      <div id='main-content'>

        <div id="home" class='content-block content-block-white'>
          <img alt="" src="images/jumbo-dev-logo.svg" />
        </div>

        <div id="project" class='content-block'>
          <h1>Project Background</h1>
          <h2>Problem Statement</h2>
          <p>Spectators are disappointed that they are unable to capture and share their fleeting moment of fame as they appear on the jumbotron.</p>
          <br />
          <h2>Research Question</h2>
          <p>How can we best capture and retrieve spectator appearances from live video feeds?</p>
          <br />
          <h2>Goal</h2>
          <p>To develop a prototype of the  Jumbo Capture applicationâ€™s core functionality.</p> 
        </div>

        <div id="team" class='content-block content-block-white'>
          <h1>Meet The Team</h1>
          <h2>Development Team</h2>

          <div class='team-photos'>
            <div class='team-photo-block'>
              <img alt="" src="images/zach.jpg" />
              <h2>Zach Barnett</h2>
            </div>
            <div class='team-photo-block'>
              <img alt="" src="images/tyler.jpg" />
              <h2>Tyler Brangman</h2>
            </div>
            <div class='team-photo-block'>
              <img alt="" src="images/james.jpg" />
              <h2>James Tarr</h2>
            </div>
            <div class='team-photo-block'>
              <img alt="" src="images/alex.jpg" />
              <h2>Alex Wilson</h2>
            </div>
          </div>
          <br class="clear"/>

          <h2>Sponsor</h2>
          <p>Kristy Verticchio</p>
          <p>Kempt LLC</p>            
          <br />
          <h2>Advisor</h2>
          <p>Carlos Morales</p>
          <p>Associate Professor, Purdue Polytechnic Institute Distance Learning Director</p>
          <br />
        </div>



        <div id="plan" class='content-block'>
          <h1>Project Plan</h1>
          <h2>Research</h2>
          <p>
            Research is focused primarily on the development of our end product, including topics such as:
            <br />
            Jumbotron systems
            <br />
            Video and Image Processing
            <br />
            Back-end (server-side) technologies
            <br />
            Front-end (client-side) technologies
            <br />
          </p>
          <br />
          <h2>Development</h2>
          <p>
            Development of our end product will result in a prototype which addresses the problem defined above.
            <br />
            Success will be measured based upon the end product's ability to provide a foundational prototype of the application's core functionality.
          </p>
          <br />
          <br />
          <h1>Timeline</h1>
          <a href="images/timeline.png"><img alt="" src="images/timeline.png" /></a>
          <br />
          <br />
          <h2>Milestone 1</h2>
          <p>PySceneDetect - clipping scenes from local drive
            <br />
            Development environments set up
          </p>
          <br />

          <h2>Milestone 2</h2>
          <p>Database setup for accessing video files
            <br />
            Store video files and do basic queries
          </p>
          <br />

          <h2>Milestone 3</h2>
          <p>Back end technologies: splitting live video, uploading to database
            <br />
            Start to front end interface
          </p>
          <br />

          <h2>End of Semester</h2>
          <p>
            Finalized front end interface &amp; back end technologies
            <br />Final testing/debugging for prototype
          </p>
        </div>

        <div id="details" class='content-block content-block-white'>
          <h1>Product Details</h1>
          <p>Our project as it stands today is a representation of the core functionalities that the Jumbo Capture application will ultimately consist of. 
          <br />
          <br />  
          The process starts with a live feed. In our prototype, this live feed is generated from a test video file via the BlackMagic Hyperdeck Studio provided by the VisualFX lab. The Hyperdeck Studio reads a specifically formatted file from a solid state drive, and then outputs this as if the saved file were live footage, via an HD/SDI or HDMI cable. 
          <br />
          <br />
          From there, the BlackMagic Web Presenter takes in the footage and converts it to a signal that can be sent to the control room hardware application as a USB webcam (in our case, our personal laptops or other development computers serve as the control room hardware). 
          <br />
          <br />
          The feed is then processed by PySceneDetect, which we have modified directly to be able to read in live video rather than a pre-existing video file. PySceneDetect analyzes the video and finds where one camera shot cuts to a different camera shot based on a certain threshold difference between one frame and the next. During this process, PySceneDetect will take a snapshot of the first and last frames of the detected clip. 
          <br />
          <br />
          There are a couple of directions in which we can take the splitting of video content from the live video source and are as follows: we split these videos along the detected scene changes live (requiring further optimization of the code we are working with) or we split these videos after the video feed has ended (utilizing the current PySceneDetect logic but sacrificing access to the videos during the event). 
          <br />
          <br />
          We have modified PySceneDetect to upload the split video clips and images to our file server rather than saving them locally in the same folder as the original video file. On the file server, these files are made available to the front end application so that they can be displayed for the user. 
          <br />
          <br />
          Our front end user interface exists as a method by which to test and ensure that the rest of our application is functional, and it additionally serves as a starting point for future development into the front end.
          </p>
        </div>
      </div>
    </div>
  </body>
</html>